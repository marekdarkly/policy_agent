# Medical Insurance Support Multi-Agent System

A production-ready LangGraph-based multi-agent system for intelligent medical insurance customer support. Features LaunchDarkly AI Config management and AWS Bedrock Knowledge Base RAG integration.

## üåü Features

- ü§ñ **Multi-Agent Orchestration** with LangGraph
- üéØ **LaunchDarkly AI Configs** - Dynamic model management per agent
- üìö **RAG with Bedrock Knowledge Base** - Semantic search over policy & provider docs
- üîÑ **Hybrid Retrieval** - Combines RAG + structured databases
- üí¨ **Interactive Terminal Chatbot** - Beautiful UI with extensive debug logging
- üìä **Observability** - Full metrics tracking via LaunchDarkly
- üîê **AWS SSO Integration** - Automatic token refresh
- üé® **Production-Ready** - Error handling, fallbacks, logging

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- AWS CLI configured with SSO
- LaunchDarkly account (free tier works)
- AWS Bedrock access (optional for RAG)

### Installation

```bash
# Clone the repository
git clone https://github.com/marekdarkly/policy_agent.git
cd policy_agent

# Complete setup (installs deps, checks AWS, verifies LaunchDarkly)
make setup
```

### Configuration

1. **Copy and configure .env**:
```bash
cp .env.example .env
# Edit .env with your LaunchDarkly SDK key
```

2. **Required environment variables**:
```bash
LAUNCHDARKLY_ENABLED=true
LAUNCHDARKLY_SDK_KEY=api-your-key-here
AWS_PROFILE=marek
AWS_REGION=us-east-1
```

3. **Optional (for RAG)**:
```bash
BEDROCK_POLICY_KB_ID=your-policy-kb-id
BEDROCK_PROVIDER_KB_ID=your-provider-kb-id
```

### Run the Chatbot

```bash
# Automatically checks AWS credentials and refreshes if needed
make run
```

That's it! The chatbot will:
- ‚úÖ Check your AWS credentials (auto-refresh if expired)
- ‚úÖ Initialize LaunchDarkly AI configs
- ‚úÖ Start the interactive chatbot

## üéØ Architecture

```
User Query
    ‚Üì
Triage Router (LaunchDarkly: triage_agent)
    ‚Üì
[Routing Decision based on confidence]
    ‚Üì
    ‚îú‚îÄ‚Üí Policy Specialist (LaunchDarkly: policy_agent)
    ‚îÇ   ‚îú‚îÄ RAG: Bedrock KB semantic search
    ‚îÇ   ‚îî‚îÄ Database: Structured policy data
    ‚îÇ
    ‚îú‚îÄ‚Üí Provider Specialist (LaunchDarkly: provider_agent)
    ‚îÇ   ‚îú‚îÄ RAG: Bedrock KB semantic search
    ‚îÇ   ‚îî‚îÄ Database: Structured provider data
    ‚îÇ
    ‚îî‚îÄ‚Üí Scheduler Specialist (LaunchDarkly: scheduler_agent)
        ‚îî‚îÄ Calendar: Available time slots
             ‚Üì
        Final Response
```

### Agent Responsibilities

| Agent | LaunchDarkly Key | RAG Enabled | Purpose |
|-------|-----------------|-------------|---------|
| **Triage Router** | `triage_agent` | ‚ùå | Query classification and routing |
| **Policy Specialist** | `policy_agent` | ‚úÖ | Coverage, benefits, claims questions |
| **Provider Specialist** | `provider_agent` | ‚úÖ | Find doctors, check network |
| **Scheduler Specialist** | `scheduler_agent` | ‚ùå | Schedule callbacks, escalate |

## üìñ Documentation

### Essential Guides

- **[LAUNCHDARKLY.md](LAUNCHDARKLY.md)** - LaunchDarkly AI Config setup
- **[BEDROCK_RAG.md](BEDROCK_RAG.md)** - RAG implementation guide
- **[RAG_SETUP_GUIDE.md](RAG_SETUP_GUIDE.md)** - Quick start for Bedrock KB
- **[AWS_BEDROCK.md](AWS_BEDROCK.md)** - Bedrock LLM configuration
- **[SDD.md](SDD.md)** - System Design Document

View all documentation:
```bash
make docs
```

## üéÆ Makefile Commands

### Common Commands

```bash
make run          # Start the chatbot (auto-checks AWS)
make chat         # Alias for 'make run'
make setup        # Complete setup from scratch
make verify       # Verify LaunchDarkly & RAG configs
make check        # Check all configurations
make info         # Show system status
make help         # Show all commands
```

### AWS Management

```bash
make aws-check    # Check AWS credentials (auto-refresh)
make aws-login    # Force AWS SSO login
make aws-info     # Show AWS identity
```

### Development

```bash
make format       # Format code with black
make lint         # Lint with ruff
make typecheck    # Type check with mypy
make quality      # Run all quality checks
make clean        # Remove cache files
```

## üí° Usage Examples

### Interactive Chatbot

```bash
make run
```

Example session:
```
üë§ You: Does my plan cover physical therapy?

üîç POLICY SPECIALIST: Retrieving policy information
üìö Retrieving policy documents via RAG...
  ‚úÖ Retrieved 5 documents (top score: 0.892)
  üìÑ Retrieved 5 relevant policy documents via RAG
    Doc 1: Score 0.892, Length 1234 chars
    
ü§ñ Assistant: Yes, your Gold Plan covers physical therapy with a $50 copay 
per visit, up to 30 visits per year. A referral from your primary care 
physician is required...
```

### Running Examples

```bash
make run-example              # Pre-defined example queries
make run-interactive-example  # Interactive mode with examples
make run-test                 # Quick test with one query
```

### Programmatic Usage

```python
from src.graph.workflow import run_workflow

result = run_workflow(
    user_message="What is my copay for seeing a specialist?",
    user_context={
        "policy_id": "POL-12345",
        "coverage_type": "Gold Plan",
        "network": "Premier Network",
        "location": "Boston, MA"
    }
)

print(result["final_response"])
```

## üîß LaunchDarkly AI Configs

### Setup

1. **Create AI Configs** in LaunchDarkly with these keys:
   - `triage_agent` - For query classification
   - `policy_agent` - For policy questions  
   - `provider_agent` - For provider lookup
   - `scheduler_agent` - For scheduling

2. **Configure each with**:
```json
{
  "model": {
    "name": "claude-3-5-sonnet",
    "parameters": {
      "temperature": 0.7,
      "maxTokens": 2000
    }
  },
  "provider": "bedrock",
  "enabled": true
}
```

3. **Verify**:
```bash
make verify-ld
```

See [LAUNCHDARKLY.md](LAUNCHDARKLY.md) for detailed instructions.

## üìö RAG (Optional but Recommended)

### Why RAG?

- üéØ **Better Accuracy**: Grounded in comprehensive documentation
- üîç **Semantic Search**: Finds relevant info even with different phrasing
- üìà **Scalability**: Add documents without code changes
- üí° **Smarter Responses**: Context from actual policy documents

### Quick Setup

1. **Create Bedrock Knowledge Bases** (AWS Console)
2. **Upload documents** to S3
3. **Add KB IDs** to `.env`
4. **Verify**:
```bash
make verify-rag
```

See [RAG_SETUP_GUIDE.md](RAG_SETUP_GUIDE.md) for step-by-step instructions.

### How RAG Works

```
Query: "Does my plan cover physical therapy?"
    ‚Üì
RAG Retrieval (Bedrock KB)
  ‚Üí Searches policy documents semantically
  ‚Üí Returns: "Physical Therapy: $50 copay, 30 visits/year, requires referral..."
    ‚Üì
Database Lookup
  ‚Üí Gets: {copay: "$50", visits_allowed: 30}
    ‚Üì
Combined Context ‚Üí LLM
    ‚Üì
Response: Comprehensive answer with citations
```

## üìÅ Project Structure

```
policy_agent/
‚îú‚îÄ‚îÄ Makefile                 # üéØ Main entry point
‚îú‚îÄ‚îÄ interactive_chatbot.py   # üí¨ Interactive terminal UI
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ agents/              # ü§ñ Agent implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ triage_router.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ policy_specialist.py      # üìö RAG-enhanced
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider_specialist.py    # üìö RAG-enhanced
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ scheduler_specialist.py
‚îÇ   ‚îú‚îÄ‚îÄ graph/               # üîÑ LangGraph workflow
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ workflow.py
‚îÇ   ‚îú‚îÄ‚îÄ tools/               # üõ†Ô∏è Backend tools
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bedrock_rag.py           # üìö RAG retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ policy_db.py             # Database
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider_db.py           # Database
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calendar.py
‚îÇ   ‚îî‚îÄ‚îÄ utils/               # ‚öôÔ∏è Utilities
‚îÇ       ‚îú‚îÄ‚îÄ aws_sso.py               # AWS authentication
‚îÇ       ‚îú‚îÄ‚îÄ bedrock_llm.py           # Bedrock LLM wrapper
‚îÇ       ‚îú‚îÄ‚îÄ launchdarkly_config.py   # LaunchDarkly integration
‚îÇ       ‚îú‚îÄ‚îÄ llm_config.py            # LLM configuration
‚îÇ       ‚îî‚îÄ‚îÄ prompts.py
‚îú‚îÄ‚îÄ examples/
‚îÇ   ‚îî‚îÄ‚îÄ run_example.py       # Example queries
‚îú‚îÄ‚îÄ verify_ld_configs.py     # LaunchDarkly verification
‚îî‚îÄ‚îÄ test_rag_integration.py  # RAG testing
```

## üîç Debug Logging

The chatbot provides extensive logging showing:

- ‚úÖ **LaunchDarkly**: Which configs retrieved, models used
- ‚úÖ **RAG**: Documents retrieved, relevance scores
- ‚úÖ **Routing**: Which agent handles the query, confidence
- ‚úÖ **AWS**: Credential status, auto-refresh
- ‚úÖ **Performance**: Token usage, latency

Example output:
```
üîç POLICY SPECIALIST: Retrieving policy information
üìö Retrieving policy documents via RAG...
  ‚úÖ Retrieved 5 documents (top score: 0.892)
üîê AWS SSO Manager initialized (profile: marek, region: us-east-1)
‚úÖ AWS credentials valid
‚ö†Ô∏è  Using default config for 'policy_agent' (config may not exist in LaunchDarkly)
```

## üé® Development

### Code Quality

```bash
make format      # Auto-format with black
make lint        # Lint with ruff
make typecheck   # Type check with mypy
make quality     # Run all checks
```

### Adding New Agents

1. Create agent file in `src/agents/`
2. Add agent node to `src/graph/workflow.py`
3. Create LaunchDarkly AI Config
4. Update routing logic in triage router

See [SDD.md](SDD.md) for architecture details.

## üîê AWS Authentication

The Makefile automatically manages AWS SSO:

```bash
# make run automatically calls aws-check first
make run
```

If credentials expired:
```
‚ö†Ô∏è  AWS credentials expired or invalid
üîÑ Refreshing AWS SSO credentials...
[Opens browser for authentication]
‚úÖ AWS SSO login successful!
üöÄ Starting chatbot...
```

Manual refresh:
```bash
make aws-login
```

## üß™ Testing & Verification

```bash
make verify       # Verify all configurations
make verify-ld    # LaunchDarkly AI configs only
make verify-rag   # RAG integration only
make test         # Run all tests
```

## üìä Observability

### LaunchDarkly Metrics

Automatically tracked for each agent:
- Token usage (input, output, total)
- Response duration
- Success/error rates
- Model performance

View in LaunchDarkly dashboard under AI Configs.

### RAG Metrics

Logged for each retrieval:
- Number of documents retrieved
- Relevance scores
- Document lengths
- Retrieval latency
- Fallback usage

## üéì How to Use

### 1. First Time Setup

```bash
make all          # Complete setup from scratch
```

### 2. Daily Use

```bash
make run          # Start chatbot (checks AWS automatically)
```

### 3. Verify Configuration

```bash
make check        # Check AWS, LaunchDarkly, RAG status
make info         # Show current system state
```

### 4. Development

```bash
make format       # Format your code
make quality      # Run quality checks
```

## üêõ Troubleshooting

### AWS Credentials Expired

```bash
make aws-login    # Force re-authentication
```

### LaunchDarkly Not Working

```bash
make verify-ld    # Check LaunchDarkly configs
```

Issues to check:
- SDK key in `.env` is correct
- AI Configs created in LaunchDarkly with correct keys
- Configs are enabled

### RAG Not Working

```bash
make verify-rag   # Check RAG configuration
```

Issues to check:
- Bedrock KB IDs in `.env`
- Knowledge Bases exist in AWS
- Data sources are synced
- IAM permissions for `bedrock:Retrieve*`

### General Issues

```bash
make info         # Show system status
make clean        # Clear cache
make setup        # Re-run setup
```

## üì¶ Dependencies

Core:
- `langgraph` - Multi-agent orchestration
- `langchain` - LLM framework
- `langchain-aws` - AWS Bedrock integration

AWS:
- `boto3` - AWS SDK
- AWS CLI with SSO configured

LaunchDarkly:
- `launchdarkly-server-sdk` - Feature flags
- `launchdarkly-server-sdk-ai` - AI Configs

## üéØ Example Queries

### Policy Questions
```
‚Ä¢ "What is my copay for seeing a specialist?"
‚Ä¢ "Does my plan cover physical therapy?"
‚Ä¢ "What's my deductible for this year?"
```

### Provider Lookup
```
‚Ä¢ "I need to find a cardiologist in Boston"
‚Ä¢ "Find me a dermatologist who accepts my insurance"
‚Ä¢ "Show me primary care doctors near me"
```

### Scheduling
```
‚Ä¢ "I need to speak with someone about my claim"
‚Ä¢ "This is urgent, I need help now"
‚Ä¢ "Can I schedule a callback?"
```

## üèóÔ∏è System Design

### Multi-Agent Flow

1. **Triage Router** analyzes query ‚Üí determines type
2. **Specialist Agent** retrieves context (RAG + DB)
3. **LLM Generation** with LaunchDarkly config
4. **Response** with citations and metadata

### LaunchDarkly Integration

Each agent:
- Retrieves its own AI Config from LaunchDarkly
- Uses configured model (can be different per agent)
- Tracks metrics automatically
- Supports A/B testing and dynamic updates

### RAG Integration

Policy & Provider specialists:
- Search Bedrock Knowledge Base semantically
- Retrieve top 5 most relevant documents
- Combine with structured database
- Generate grounded responses

## üîÑ Workflow

```mermaid
graph TD
    A[User Query] --> B[Triage Router]
    B -->|Policy Question| C[Policy Specialist]
    B -->|Provider Lookup| D[Provider Specialist]
    B -->|Complex/Escalate| E[Scheduler Specialist]
    
    C -->|RAG| F[Bedrock Policy KB]
    C -->|DB| G[Policy Database]
    F --> H[Combined Context]
    G --> H
    H --> I[LLM with LD Config]
    
    D -->|RAG| J[Bedrock Provider KB]
    D -->|DB| K[Provider Database]
    J --> L[Combined Context]
    K --> L
    L --> M[LLM with LD Config]
    
    E --> N[Calendar System]
    N --> O[LLM with LD Config]
    
    I --> P[Response]
    M --> P
    O --> P
```

## üé® Customization

### Add New Agent

1. Create agent file in `src/agents/`
2. Add routing logic in `triage_router.py`
3. Add node to `src/graph/workflow.py`
4. Create LaunchDarkly AI Config with key: `{agent}_agent`

### Modify Prompts

Edit `src/utils/prompts.py` to customize agent behavior.

### Change LLM Models

Update in LaunchDarkly AI Config (no code changes needed):
- Different models per agent
- A/B test configurations
- Dynamic updates

## üìà Production Deployment

### Environment Variables

```bash
# Required
LAUNCHDARKLY_ENABLED=true
LAUNCHDARKLY_SDK_KEY=api-xxx
AWS_PROFILE=production
AWS_REGION=us-east-1

# Optional RAG
BEDROCK_POLICY_KB_ID=KB123
BEDROCK_PROVIDER_KB_ID=KB456
RAG_TOP_K=5

# LLM Fallbacks (used if LD config missing)
LLM_PROVIDER=bedrock
LLM_MODEL=claude-3-5-sonnet
```

### Deployment Checklist

- [ ] LaunchDarkly AI Configs created for all 4 agents
- [ ] AWS credentials configured (IAM role or SSO)
- [ ] Bedrock Knowledge Bases created and synced (optional)
- [ ] Environment variables configured
- [ ] Dependencies installed: `make install`
- [ ] Configuration verified: `make verify`
- [ ] Test run successful: `make run-test`

### Monitoring

- **LaunchDarkly Dashboard**: View AI Config metrics
- **AWS CloudWatch**: Monitor Bedrock API calls
- **Application Logs**: Debug logs from chatbot

## ü§ù Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Make changes and test: `make quality`
4. Commit: `git commit -m 'Add amazing feature'`
5. Push: `git push origin feature/amazing-feature`
6. Create Pull Request

## üìù License

MIT License - see [LICENSE](LICENSE) file

## üôè Acknowledgments

- **LangChain** - LLM framework
- **LangGraph** - Multi-agent orchestration
- **LaunchDarkly** - AI Config management
- **AWS Bedrock** - LLM inference and RAG

## üöÄ Quick Reference Card

```bash
# Start here
make setup        # Initial setup
make run          # Run chatbot

# Verification
make verify       # Check everything
make info         # System status

# Development  
make format       # Format code
make quality      # All checks

# Cleanup
make clean        # Remove cache
make clean-all    # Nuclear option
```

---

**Ready to chat?** Run `make run` and start asking questions! üéâ
